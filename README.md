# SSL-pretraining-separation
This is the official repository of [SELF-SUPERVISED PRE-TRAINING REDUCES LABEL PERMUTATION INSTABILITY OF SPEECH SEPARATION
](https://arxiv.org/pdf/2010.15366.pdf), which is not organized yet. Although the code cannot be run directly, it can show the detailed experimental settings not described in the paper.

The corpuses are prepared following run.sh in [asteroid/egs/librimix/ConvTasNet/](https://github.com/asteroid-team/asteroid/tree/master/egs/librimix/ConvTasNet) and [asteroid/egs/wham/ConvTasNet/](https://github.com/asteroid-team/asteroid/tree/master/egs/wham/ConvTasNet).
